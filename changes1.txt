def preprocess_data(data):
    """
    Preprocess the data to clean and format it.
    - Convert datetime columns.
    - Assign clean roles for internal and external participants.
    """

    # Convert time columns to datetime with error handling
    data['START_TIME'] = pd.to_datetime(data['START_TIME'], errors='coerce')
    data['END_TIME'] = pd.to_datetime(data['END_TIME'], errors='coerce')
    data['ROLODEX_CREATED_TIME'] = pd.to_datetime(data['ROLODEX_CREATED_TIME'], errors='coerce')

    # Drop rows with invalid datetime values
    data = data.dropna(subset=['START_TIME', 'END_TIME', 'ROLODEX_CREATED_TIME'])

    # Fill missing FIRMWIDE_ID with EMAIL_ADDRESS if available
    data['FIRMWIDE_ID'] = data['FIRMWIDE_ID'].fillna(data['EMAIL_ADDRESS'])

    # Role Assignment Logic
    def assign_roles(row):
        if row['IS_EMPLOYEE']:  # Internal Participants
            return row['TITLE'] if pd.notna(row['TITLE']) else (
                row['FUNCTIONAL_ROLE'] if pd.notna(row['FUNCTIONAL_ROLE']) else 'Default Role'
            )
        else:  # External Participants
            return row['FUNCTIONAL_ROLE'] if pd.notna(row['FUNCTIONAL_ROLE']) else (
                row['TITLE'] if pd.notna(row['TITLE']) else 'Default Role'
            )

    # Apply role assignment
    data['ROLE'] = data.apply(assign_roles, axis=1)

    return data

















from collections import Counter

def calculate_participants_features(old_participants, old_roles, old_is_employee,
                                    new_participants, new_roles, new_is_employee, role_weights, role_threshold=10):
    """
    Calculate matching percentage and overlap of participants for internal and external participants separately.

    Parameters:
    - old_participants: List of participants (firmwide IDs) in the old interaction.
    - old_roles: List of roles in the old interaction.
    - old_is_employee: List of bools indicating internal participants in the old interaction.
    - new_participants: List of participants (firmwide IDs) in the new interaction.
    - new_roles: List of roles in the new interaction.
    - new_is_employee: List of bools indicating internal participants in the new interaction.
    - role_weights: Dictionary of role weights for prioritization.
    - role_threshold: Weight threshold for ignoring non-matching participants.

    Returns:
    - internal_match_percentage, external_match_percentage
    - internal_overlap, external_overlap
    """
    def get_matching_percentage(old_data, new_data):
        """Calculate matching percentage based on (firmwide_id, role)."""
        matches = len(set(old_data) & set(new_data))
        total_old = len(old_data)
        return (matches / total_old) * 100 if total_old > 0 else 0

    def get_overlap_percentage(old_data, new_data, threshold):
        """
        Calculate overlap percentage while ignoring high-role-weight non-matching participants.
        """
        # Filter out unmatched new participants with high role weight
        old_fw_ids_roles = set((fw_id, role) for fw_id, role, _ in old_data)
        filtered_new = [(fw_id, role) for fw_id, role, weight in new_data
                        if (fw_id, role) in old_fw_ids_roles or weight <= threshold]

        total_union = len(set(old_fw_ids_roles) | set(filtered_new))
        intersection = len(set(old_fw_ids_roles) & set(filtered_new))

        return (intersection / total_union) * 100 if total_union > 0 else 0

    def prepare_data(participants, roles, is_employee, is_internal, role_weights):
        """Prepare combined (firmwide_id, role, weight) data for internal/external participants."""
        return [(fw_id, role, role_weights.get(role, 1))
                for fw_id, role, emp in zip(participants, roles, is_employee)
                if emp == is_internal]

    # Prepare data for internal participants
    old_internal_data = prepare_data(old_participants, old_roles, old_is_employee, True, role_weights)
    new_internal_data = prepare_data(new_participants, new_roles, new_is_employee, True, role_weights)

    # Prepare data for external participants
    old_external_data = prepare_data(old_participants, old_roles, old_is_employee, False, role_weights)
    new_external_data = prepare_data(new_participants, new_roles, new_is_employee, False, role_weights)

    # Internal Features
    internal_match_percentage = get_matching_percentage(
        [(fw_id, role) for fw_id, role, _ in old_internal_data],
        [(fw_id, role) for fw_id, role, _ in new_internal_data]
    )
    internal_overlap = get_overlap_percentage(old_internal_data, new_internal_data, role_threshold)

    # External Features
    external_match_percentage = get_matching_percentage(
        [(fw_id, role) for fw_id, role, _ in old_external_data],
        [(fw_id, role) for fw_id, role, _ in new_external_data]
    )
    external_overlap = get_overlap_percentage(old_external_data, new_external_data, role_threshold)

    return internal_match_percentage, external_match_percentage, internal_overlap, external_overlap





internal_match, external_match, internal_overlap, external_overlap = calculate_participants_features(
    old_participants=int1['PARTICIPANTS'],
    old_roles=int1['FUNCTIONAL_ROLES'],
    old_is_employee=int1['IS_EMPLOYEE'],
    new_participants=int2['PARTICIPANTS'],
    new_roles=int2['FUNCTIONAL_ROLES'],
    new_is_employee=int2['IS_EMPLOYEE'],
    role_weights=role_weights,
    role_threshold=10  # Threshold can be adjusted as per requirement
)







def aggregate_interactions(data):
    """Aggregate rows corresponding to the same ID into a single interaction."""
    def aggregate_func(group):
        return pd.Series({
            'START_TIME': group['START_TIME'].iloc[0],
            'END_TIME': group['END_TIME'].iloc[0],
            'ROLODEX_CREATED_TIME': group['ROLODEX_CREATED_TIME'].iloc[0],
            'SUBJECT': group['SUBJECT'].iloc[0],
            'TAGS': group['TAGS'].iloc[0],
            'PURPOSE': group['PURPOSE'].iloc[0],
            'PARTICIPANTS': group['FIRMWIDE_ID'].dropna().tolist(),
            'IS_EMPLOYEE': group['IS_EMPLOYEE'].tolist(),
            'FUNCTIONAL_ROLES': group['ROLE'].tolist()  # Include cleaned ROLE column
        })
    
    return data.groupby('ID', as_index=False).apply(aggregate_func).reset_index(drop=True)
