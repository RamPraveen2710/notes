import pandas as pd
import numpy as np
import ast
from datetime import datetime, timedelta

# Load the processed interaction & readership data
interaction_file = "processed_interactions.csv"
readership_file = "processed_readership.csv"

interactions_df = pd.read_csv(interaction_file, dtype=str)
readership_df = pd.read_csv(readership_file, dtype=str)

# Convert lists stored as strings back to lists
list_columns = ["FirmwideIDs", "ParticipantNames", "EmployeeInd", "Roles", "RICs", "TickersDiscussed", "EMCM_Tickers"]
for col in list_columns:
    interactions_df[col] = interactions_df[col].apply(lambda x: ast.literal_eval(x) if pd.notna(x) and x.startswith("[") else [])

# Convert date columns to datetime
interactions_df["StartTime"] = pd.to_datetime(interactions_df["StartTime"], errors="coerce")
readership_df["StartDate"] = pd.to_datetime(readership_df["StartDate"], errors="coerce")

# ✅ Step 2: Identify Interactions with the Searched Ticker & Check 30-Day Readership Window
def get_ticker_matched_interactions(ticker, interactions_df, readership_df):
    """
    Find interactions where an external participant is present and the TickerDiscussed, RIC, or EMCM_Ticker 
    contains the searched ticker. Then, check if any participant had a readership event within 30 days.
    """
    matched_interactions = set()
    external_participants = set()
    interaction_scores = {}

    # Filter readership data for the ticker
    readership_filtered = readership_df[readership_df["TickerRead"].str.contains(ticker, case=False, na=False)]

    for _, row in interactions_df.iterrows():
        # Check if the interaction contains the searched ticker in RICs, TickerDiscussed, or EMCM_Tickers
        if any(ticker.lower() in str(value).lower() for value in row["TickersDiscussed"] + row["RICs"] + row["EMCM_Tickers"]):
            # Ensure at least one external participant exists
            if any(emp == "0" for emp in row["EmployeeInd"]):  
                matched_interactions.add(row["InteractionID"])
                external_participants.update(row["FirmwideIDs"])  

                # Check if any participant has a readership event within 30 days
                for participant in row["FirmwideIDs"]:
                    if participant in set(readership_filtered["FirmwideID"]):
                        last_read_date = readership_filtered.loc[readership_filtered["FirmwideID"] == participant, "StartDate"].max()
                        if pd.notna(last_read_date) and abs((row["StartTime"] - last_read_date).days) <= 30:
                            interaction_scores[row["InteractionID"]] = 95  # Higher Score for Recent Readership
                            break  # One match is enough
                else:
                    interaction_scores[row["InteractionID"]] = 80  # Lower Score for non-recent readership

    matched_df = interactions_df[interactions_df["InteractionID"].isin(matched_interactions)].copy()
    matched_df["Score"] = matched_df["InteractionID"].map(interaction_scores)  

    remaining_interactions_df = interactions_df[~interactions_df["InteractionID"].isin(matched_interactions)].copy()

    return matched_df, remaining_interactions_df, external_participants

# ✅ Step 3: Identify Covering Analyst Interactions
def get_analyst_matched_interactions(ticker, remaining_interactions_df, external_participants):
    """
    Identify interactions where:
    - The internal participant is a covering analyst for the given ticker.
    - At least one external participant is present from our identified list.
    - Assign scores based on subject relevance.
    """
    covering_analysts = {
        "NVDA": "874459",
        "TSLA": "10327",
        "MSFT": "153425",
        "AAPL": "1161226"
    }

    matched_interactions = set()
    interaction_scores = {}

    if ticker not in covering_analysts:
        print(f"No covering analyst found for {ticker}")
        return pd.DataFrame(), remaining_interactions_df

    covering_analyst_id = covering_analysts[ticker]

    for _, row in remaining_interactions_df.iterrows():
        internal_firmwide_ids = {fid for fid, emp in zip(row["FirmwideIDs"], row["EmployeeInd"]) if emp == "1"}
        external_firmwide_ids = {fid for fid, emp in zip(row["FirmwideIDs"], row["EmployeeInd"]) if emp == "0"}

        # Check if covering analyst is internal
        if covering_analyst_id in internal_firmwide_ids:
            # Ensure at least one external participant is in our identified list
            if external_firmwide_ids & external_participants:  
                matched_interactions.add(row["InteractionID"])

                # Assign scores based on subject match
                subject_text = str(row["Subject"]).lower()
                if "nvda" in subject_text or "nvidia" in subject_text:
                    interaction_scores[row["InteractionID"]] = 90  # Strong Context
                else:
                    interaction_scores[row["InteractionID"]] = 75  # Weaker Context

    matched_df_analyst = remaining_interactions_df[remaining_interactions_df["InteractionID"].isin(matched_interactions)].copy()
    matched_df_analyst["Score"] = matched_df_analyst["InteractionID"].map(interaction_scores)

    remaining_interactions_df = remaining_interactions_df[~remaining_interactions_df["InteractionID"].isin(matched_interactions)].copy()

    return matched_df_analyst, remaining_interactions_df

# ✅ Run All Steps
searched_ticker = "NVDA"

# Step 2 (Modified): Get initial interactions based on Ticker + 30-Day Check
matched_df_ticker, remaining_interactions_df, external_participants = get_ticker_matched_interactions(
    searched_ticker, interactions_df, readership_df
)

# Step 3: Get interactions with Covering Analyst
matched_df_analyst, remaining_interactions_df = get_analyst_matched_interactions(
    searched_ticker, remaining_interactions_df, external_participants
)

# ✅ Final Merging of Results
final_results = pd.concat([matched_df_ticker, matched_df_analyst], ignore_index=True)

# ✅ Save the results
final_results.to_csv("potential_interactions_nvda.csv", index=False)

# ✅ Print Output
print(f"Final potential interactions found for '{searched_ticker}':", final_results.shape[0])








import numpy as np
import pandas as pd
from sentence_transformers import SentenceTransformer

# Load interactions dataset
interaction_file = "processed_interactions.csv"
interactions_df = pd.read_csv(interaction_file, dtype=str)

# Ensure Interaction_Text is available
if "Interaction_Text" not in interactions_df.columns:
    raise ValueError("Missing Interaction_Text column in dataset!")

# Load pre-trained Sentence Transformer model
model = SentenceTransformer("all-MiniLM-L6-v2")  # You can use any suitable model

# Compute embeddings for all interactions
interaction_texts = interactions_df["Interaction_Text"].fillna("").tolist()
embeddings = model.encode(interaction_texts, convert_to_numpy=True)

# Save embeddings & corresponding Interaction IDs
np.save("interaction_embeddings.npy", embeddings)
interactions_df["InteractionID"].to_csv("interaction_ids.csv", index=False)

print(f"Stored {len(embeddings)} interaction embeddings successfully!")
