import pandas as pd
import numpy as np
from itertools import combinations

# Load Excel file
def load_excel(file_path):
    """Load the Excel file into a pandas DataFrame."""
    return pd.read_excel(file_path)

# Preprocess data
def preprocess_data(data):
    """Preprocess the data to clean and format it."""
    data['START_TIME'] = pd.to_datetime(data['START_TIME'])
    data['END_TIME'] = pd.to_datetime(data['END_TIME'])
    data['FIRMWIDE_ID'] = data['FIRMWIDE_ID'].fillna(data['EMAIL'])
    data['FUNCTIONAL_ROLE'] = data['FUNCTIONAL_ROLE'].fillna(data['TITLE']).fillna('Default Role')
    return data

# Aggregate interactions
def aggregate_interactions(data):
    """Aggregate rows corresponding to the same ID into a single interaction."""
    def aggregate_func(group):
        return pd.Series({
            'ATTRIBUTE_VALUE': group['ATTRIBUTE_VALUE'].iloc[0],
            'START_TIME': group['START_TIME'].iloc[0],
            'END_TIME': group['END_TIME'].iloc[0],
            'SUBJECT': group['SUBJECT'].iloc[0],
            'TAGS': list(set(tag for tags in group['TAGS'].dropna() for tag in tags.split(','))),
            'PURPOSE': group['PURPOSE'].iloc[0],
            'PARTICIPANTS': group['FIRMWIDE_ID'].dropna().tolist(),
            'IS_EMPLOYEE': group['IS_EMPLOYEE'].tolist(),
            'FUNCTIONAL_ROLES': group['FUNCTIONAL_ROLE'].tolist()
        })
    
    return data.groupby(['ATTRIBUTE_VALUE', 'ID'], as_index=False, group_keys=False).apply(aggregate_func)

# Extract pairwise features for all interactions within the same ATTRIBUTE_VALUE
def extract_pairwise_features_for_all(data):
    """Extract pairwise features for all ATTRIBUTE_VALUEs."""
    all_features = []

    unique_attribute_values = data['ATTRIBUTE_VALUE'].unique()
    
    for attribute_value in unique_attribute_values:
        group = data[data['ATTRIBUTE_VALUE'] == attribute_value]
        indices = group.index.tolist()
        pair_indices = [(i, j) for i in indices for j in indices if i != j]

        for idx1, idx2 in pair_indices:
            interaction1 = group.loc[idx1]
            interaction2 = group.loc[idx2]
            features = compare_interactions(interaction1, interaction2)
            features['ATTRIBUTE_VALUE'] = attribute_value  # Add ATTRIBUTE_VALUE for context
            all_features.append(features)

    return pd.DataFrame(all_features)

# Compare two interactions
def compare_interactions(interaction1, interaction2):
    """Compute feature comparisons between two interactions."""
    time_diff = abs((interaction1['START_TIME'] - interaction2['START_TIME']).total_seconds() / 60)  # Time difference in minutes
    overlap = calculate_overlap(interaction1['START_TIME'], interaction1['END_TIME'],
                                 interaction2['START_TIME'], interaction2['END_TIME'])

    features = {
        'Interaction1_ID': interaction1['ID'],
        'Interaction2_ID': interaction2['ID'],
        'Time Difference': time_diff,
        'Overlap Percentage': overlap,
        # Add more features here, such as Subject Matching, Tag Matching, etc.
    }
    return features

# Calculate time overlap
def calculate_overlap(start1, end1, start2, end2):
    """Calculate overlap percentage between two time intervals."""
    overlap_start = max(start1, start2)
    overlap_end = min(end1, end2)
    overlap_duration = max(0, (overlap_end - overlap_start).total_seconds() / 60)  # Duration in minutes
    total_duration = (end1 - start1).total_seconds() / 60
    return (overlap_duration / total_duration) * 100 if total_duration > 0 else 0

# Main function to process and extract features for all ATTRIBUTE_VALUEs
def main(file_path, output_csv):
    data = load_excel(file_path)
    data = preprocess_data(data)
    aggregated_data = aggregate_interactions(data)
    features = extract_pairwise_features_for_all(aggregated_data)
    features.to_csv(output_csv, index=False)
    print(f"Features saved to {output_csv}")

# Example usage
file_path = 'your_excel_file.xlsx'  # Replace with your Excel file path
output_csv = 'interaction_features.csv'  # Replace with desired output CSV path
main(file_path, output_csv)
